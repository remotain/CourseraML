{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "import re\n",
    "import os\n",
    "import nltk, nltk.stem.porter\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Anyone knows how much it costs to host a web portal ?\n",
      ">\n",
      "Well, it depends on how many visitors you're expecting.\n",
      "This can be anywhere from less than 10 bucks a month to a couple of $100. \n",
      "You should checkout http://www.rackspace.com/ or perhaps Amazon EC2 \n",
      "if youre running something big..\n",
      "\n",
      "To unsubscribe yourself from this mailing list, send an email to:\n",
      "groupname-unsubscribe@egroups.com\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mail1 = open(\"data/emailSample1.txt\", 'r').read()\n",
    "print mail1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(email):\n",
    "    \n",
    "    # Lower casing \n",
    "    email = email.lower()\n",
    "    \n",
    "    # Remove traling characters \n",
    "    email = re.sub('[\\n\\r]', '', email)\n",
    "        \n",
    "    # Stripping HTML\n",
    "    email = re.sub('<[^<>]+>', '', email)\n",
    "    \n",
    "    # Normalizing URL\n",
    "    email = re.sub('(http|https)://[^\\s]*', 'httpaddr', email)\n",
    "    \n",
    "    # Normalizing email addresses\n",
    "    email = re.sub('[^\\s]+@[^\\s]+', 'emailaddr', email)    \n",
    "    \n",
    "    # Normalizing numbers\n",
    "    email = re.sub('[0-9]+', 'number ', email)\n",
    "    \n",
    "    # Normalizing dollars\n",
    "    email = re.sub('[$]+', 'dollar ', email)\n",
    "    \n",
    "    # Removal non-word\n",
    "    email = re.sub('[^a-zA-Z0-9]', ' ', email);\n",
    "\n",
    "    # Remove white space in excess\n",
    "    email = re.sub('^\\s', '', email)\n",
    "    \n",
    "    email = re.sub('\\s\\s+', ' ', email)\n",
    "\n",
    "    #print email\n",
    "    \n",
    "    # Split\n",
    "    tokens = re.split(' ', email)\n",
    "    \n",
    "    # Word stemming\n",
    "    stemmer = nltk.stem.porter.PorterStemmer()\n",
    "    \n",
    "    token_list = []\n",
    "    \n",
    "    for word in tokens:\n",
    "        \n",
    "        token_list.append(str(stemmer.stem(word)))\n",
    "    \n",
    "    return token_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess(mail1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab(file_name = \"data/vocab.txt\"):\n",
    "    vocab_dict = {}\n",
    "    with open(\"data/vocab.txt\", 'r') as f:\n",
    "        for line in f:\n",
    "            (val, key) = line.split()\n",
    "            vocab_dict[key] = int(val)\n",
    "            \n",
    "    return vocab_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_dict = get_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mail_to_vocab_idx(mail, vocab):\n",
    "    idx = []\n",
    "    token_list = preprocess(mail)\n",
    "    idx = [ vocab[token] for token in token_list if token in vocab ] \n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_list=mail_to_vocab_idx(mail1,vocab_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting features from email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idx_to_features(idx_list, size = len(vocab_dict)):\n",
    "    \n",
    "    features = np.zeros(size)\n",
    "    \n",
    "    for idx in idx_list:\n",
    "        features[idx] = 1\n",
    "    \n",
    "    return features\n",
    "\n",
    "def email_to_features(mail, vocab_dict):\n",
    "    idx_list = mail_to_vocab_idx(mail1,vocab_dict)    \n",
    "    return idx_to_features(idx_list, len(vocab_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of feature vector: 1899\n",
      "Length of zero entries: 1854 \n",
      "Length of non-zero entries: 45 \n"
     ]
    }
   ],
   "source": [
    "mail1 = open(\"data/emailSample1.txt\", 'r').read()\n",
    "vocab_dict = get_vocab()\n",
    "features = email_to_features(mail1,vocab_dict)\n",
    "unique, counts = np.unique(features, return_counts=True)\n",
    "print \"Length of feature vector: %i\" % len(features) \n",
    "print \"Length of zero entries: %i \" % counts[0]\n",
    "print \"Length of non-zero entries: %i \" % counts[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training SVM for Spam Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTrain=scipy.io.loadmat('data/spamTrain.mat')\n",
    "X=dataTrain['X']\n",
    "y=dataTrain['y']\n",
    "\n",
    "dataTest=scipy.io.loadmat('data/spamTest.mat')\n",
    "Xtest=dataTest['Xtest']\n",
    "ytest=dataTest['ytest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "svc = svm.SVC(C=0.1, kernel='linear', verbose=False)\n",
    "svc.fit(X, y.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accurancy: 99.83 %\n",
      "Test set accurancy: 98.90 %\n"
     ]
    }
   ],
   "source": [
    "print \"Training set accurancy: %.2f %%\" % (100* svc.score(X,y))\n",
    "print \"Test set accurancy: %.2f %%\" % (100* svc.score(Xtest,ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 15 most important words to classify a spam e-mail are:\n",
      "['otherwis', 'clearli', 'remot', 'gt', 'visa', 'base', 'doesn', 'wife', 'previous', 'player', 'mortgag', 'natur', 'll', 'futur', 'hot']\n",
      "\n",
      "The 15 least important words to classify a spam e-mail are:\n",
      "['http', 'toll', 'xp', 'ratio', 'august', 'unsubscrib', 'useless', 'numberth', 'round', 'linux', 'datapow', 'wrong', 'urgent', 'that', 'spam']\n"
     ]
    }
   ],
   "source": [
    "# [::-1] revert the np array!!\n",
    "\n",
    "print \"The 15 most important words to classify a spam e-mail are:\"\n",
    "print [vocab_dict.keys()[vocab_dict.values().index(idx)] for idx in np.argsort(svc.coef_).flatten()[::-1][:15]]\n",
    "print \"\"\n",
    "print \"The 15 least important words to classify a spam e-mail are:\"\n",
    "print [vocab_dict.keys()[vocab_dict.values().index(idx)] for idx in np.argsort(svc.coef_).flatten()[::-1][-15:]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
